[{"title":"Typeform for entry field","author":"","status":"Spike","priority":"Medium","created_date":1638455750,"updated_date":1638455750,"id":1,"content":"\n\nentry field (from entries-define.yaml) to form for web\n\nfield example\n\n```yaml\nfields:\n  - title: Title\n  - author: String\n  - content: Body\n  - status: Flow\n  - priority: Flow\n  - created_date: Date\n  - updated_date: Date\n```\n\nlibrary such as:\n\n- https://github.com/formium/formik\n- https://github.com/unform/unform\n\n\n","type":"story"},{"title":"Quake render for Entry","author":"","status":"Done","priority":"Medium","created_date":1638455944,"updated_date":1638455944,"id":2,"content":"\n\nfor examples:\n\nReact Notion Render:\n\n- [https://github.com/splitbee/react-notion](https://github.com/splitbee/react-notion)\n- [https://github.com/NotionX/react-notion-x](https://github.com/NotionX/react-notion-x)\n\n\n","type":"story"},{"title":"page link support","author":"","status":"Done","priority":"Medium","created_date":1638456059,"updated_date":1638456059,"id":3,"content":"\n\nsuch as page link in Notion: `[[]]`\n\nsome_link [[issue:0001-demo]] fdas\n","type":"story"},{"title":"flowy item","author":"","status":"Done","priority":"Low","created_date":1638464878,"updated_date":1638466489,"id":4,"content":"\n\n# show items\n\n\n```javascript\n```\n\n\n","type":"story"},{"title":"navigator for webapp","author":"","status":"Todo","priority":"Low","created_date":1638474354,"updated_date":1638474354,"id":5,"content":"\n\nreplace current home with new UI\n\n\n","type":"story"},{"title":"monorep with nxjs","author":"","status":"Doing","priority":"Low","created_date":1638481845,"updated_date":1638481845,"id":6,"content":"\n\n\nsimple: [https://nx.dev/l/a/getting-started/nx-setup](https://nx.dev/l/a/getting-started/nx-setup)\n\n\n","type":"story"},{"title":"migration Quake.toml to .quake.yaml","author":"","status":"Done","priority":"High","created_date":1638488577,"updated_date":1638488577,"id":7,"content":"\n\nas you know, we have to differing config\n\n","type":"story"},{"title":"add images support","author":"","status":"Todo","priority":"Low","created_date":1638536503,"updated_date":1638536503,"id":8,"content":"\n\n\nas title\n\n","type":"story"},{"title":"pdf spike","author":"","status":"Todo","priority":"Low","created_date":1638536525,"updated_date":1638536525,"id":9,"content":"\n\n\n## Rust\n\nread pdf: https://github.com/pdf-rs/pdf\n\npdf information: https://github.com/jrmuizel/pdf-extract\n\n## pdf to text\n\n- pdf with quake\n- pdf to text\n\n### pdfminer.six\n\n- link: [https://github.com/pdfminer/pdfminer.six](https://github.com/pdfminer/pdfminer.six)\n- languages: Python\n- intro: Pdfminer.six is a community maintained fork of the original PDFMiner. It is a tool for extracting information from PDF documents.\n  It focuses on getting and analyzing text data. Pdfminer.six extracts the text from a page directly from the sourcecode of the PDF.\n  It can also be used to get the exact location, font or color of the text.\n\n### pdf-extract\n\n- link: [https://github.com/CrossRef/pdfextract](https://github.com/CrossRef/pdfextract)\n- languages: Ruby\n- A tool and library that can extract various areas of text from a PDF, especially a scholarly article PDF. It performs structural\n- analysis to determine column bounds, headers, footers, sections, titles and so on. It can analyse and categorise sections into\n- reference and non-reference sections and can split reference sections into individual references.\n","type":"story"},{"title":"crawl links","author":"","status":"Spike","priority":"Low","created_date":1638536562,"updated_date":1638536562,"id":10,"content":"\n","type":"story"},{"title":"custom path for entry","author":"","status":"Todo","priority":"Low","created_date":1638550176,"updated_date":1638550176,"id":11,"content":"\n\nadd config to entries define.\n","type":"story"},{"title":"replace search api with entries list csv","author":"","status":"Done","priority":"Low","created_date":1638550611,"updated_date":1638550611,"id":12,"content":"\n\ncreate simple json builder from csv\n\n","type":"story"},{"title":"Infinite Scroll for Dashboard","author":"","status":"Done","priority":"High","created_date":1638629198,"updated_date":1638629198,"id":13,"content":"\n\n","type":"story"},{"title":"watch dir & feed to searchengine","author":"Phodal","status":"Done","priority":"High","created_date":1638631185,"updated_date":1638631185,"id":14,"content":"\n","type":"story"},{"title":"dockerfile for auto deploy","author":"","status":"Todo","priority":"Low","created_date":1638648571,"updated_date":1638648571,"id":15,"content":"\n","type":"story"},{"title":"timeline for annual review","author":"Phodal","status":"Done","priority":"Low","created_date":1638660789,"updated_date":1638660789,"id":16,"content":"\n\nrefs library:\n\noverview by points\n\n- https://github.com/prabhuignoto/react-chrono\n\nwith calendar:\n\n- https://github.com/namespace-ee/react-calendar-timeline\n\n","type":"story"},{"title":"transflow with function generate","author":"Phodal","status":"Doing","priority":"Low","created_date":1638669804,"updated_date":1638669804,"id":17,"content":"\n\n1. transforms.js for loading and process\n\n2. use codeshift to generate different data struct\n\n3. import transform.js to core\n\n4. provide some commons functions\n\n\n## Define flows:\n\n1. use QuakeParser to parse block and generate function\n2. function binding to `.yaml` or `.js` files\n3. loading to webserver for core.\n\none commmits\n\n```bash\ndefine { from(\"todo\", \"blog\", \"yiki\").to(<quake-calendar>) }\n```\n\nsecond commits\n\n```\ndefine {\n    from(\"todo\").to(\"simple_todo\"),\n    from(\"simple_todo\", \"todo\").to(<quake-calendar>);\n}    \n```\n\nparsed:\n\n```json\n{\n  \"routes\": [\n    {\n      \"from\": [\n        {\n          \"field\": \"\"\n        }\n      ],\n      \"to\": \"\",\n      \"name\": \"\",\n      \"is_end_way\": \"\"\n    }\n  ],\n  \"defines\": {\n    \"todo\": {},\n    \"blog\": {},\n    \"yiki\": {}\n  },\n  \"target\": \"quake-calendar\"\n}\n```\n\nsimple query for expression: `simple(\"${body.address.street}\")`； \n\nalso generate `quake-calendar` date_type from TypeScript/JavaScript to Yaml.\n\n```typescript\ninterface QuakeCalendar {\n   input: {\n      data: \"\"\n   },\n   output: {\n      event: \"\"\n   } \n}\n```\n\nand also output defines if it will save:\n\n```javascript\n\n```\n\n## Camel DSL examples\n\nYAML: https://camel.apache.org/components/3.13.x/others/yaml-dsl.html\n\n```yaml\n- from: (1)\n    uri: \"direct:start\"\n    steps: (2)\n      - filter:\n          expression:\n            simple: \"${in.header.continue} == true\"\n          steps: (2)\n            - to:\n                uri: \"log:filtered\"\n      - to:\n          uri: \"log:original\"\n```\n\n","type":"story"},{"title":"tql for search query","author":"","status":"Spike","priority":"Low","created_date":1638723238,"updated_date":1638723238,"id":18,"content":"\n\n\ncreate a simple Query for custom search\n\n\n\n","type":"story"},{"title":"filter for flow codegen","author":"","status":"Spike","priority":"Low","created_date":1638957696,"updated_date":1638957696,"id":19,"content":"\n\n## JSON Filter\n\n[https://platform.data-axle.com/people/docs/filter_dsl](https://platform.data-axle.com/people/docs/filter_dsl)\n\nsamples 1\n\n```bash\ncurl -X GET https://api.data-axle.com/v1/people/search -d '{\n  \"filter\": {\n    \"relation\": \"equals\",\n    \"attribute\": \"state\",\n    \"value\": \"NY\",\n    \"negated\": true\n  }\n}'\n```\n\nsamples 2\n\n```bash\ncurl -X GET https://api.data-axle.com/v1/people/search -d '{\n  \"filter\": {\n    \"relation\": \"in\",\n    \"attribute\": \"state\",\n    \"value\": [\"WA\", \"OR\", \"ID\", \"CA\"]\n  }\n}'\n```\n\nmap {\n  created_date -> start_time\n}\n","type":"story"},{"title":"search rule 'filterableAttributes' by entry type","author":"","status":"Done","priority":"Low","created_date":1638960391,"updated_date":1638960391,"id":20,"content":"\n\nwhen feed settings to project, we need to load entry_defines, add `filterableAttributes` for display\n\nin default, it can be :\n\n```json\n  \"filterableAttributes\": [\n    \"created_date\",\n    \"updated_date\"\n  ]\n```\n\n\n","type":"story"},{"title":"make transflow in auto_suggest api","author":"","status":"Spike","priority":"Low","created_date":1639006780,"updated_date":1639006780,"id":21,"content":"\n\n\n\n\n","type":"story"},{"title":"filter for parse item","author":"","status":"Spike","priority":"Low","created_date":1639042348,"updated_date":1639042348,"id":22,"content":"\n\n## MeiliSearch Query Parser\n\nMeiliSearch Core: [https://github.com/meilisearch/milli](https://github.com/meilisearch/milli)\n\na concurrent indexer combined with fast and relevant search algorithms\n\nBNF:\n\n```text\nfilter         = expression ~ EOF\nexpression     = or\nor             = and (~ \"OR\" ~ and)\nand            = not (~ \"AND\" not)*\nnot            = (\"NOT\" ~ not) | primary\nprimary        = (WS* ~ \"(\"  expression \")\" ~ WS*) | geoRadius | condition | to\ncondition      = value (\"==\" | \">\" ...) value\nto             = value value TO value\nvalue          = WS* ~ ( word | singleQuoted | doubleQuoted) ~ WS*\nsingleQuoted   = \"'\" .* all but quotes \"'\"\ndoubleQuoted   = \"\\\"\" .* all but double quotes \"\\\"\"\nword           = (alphanumeric | _ | - | .)+\ngeoRadius      = WS* ~ \"_geoRadius(\" ~ WS* ~ float ~ WS* ~ \",\" ~ WS* ~ float ~ WS* ~ \",\" float ~ WS* ~ \")\"\n```\n\n## Elasticsearch Range Query\n\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-range-query.html\n\n\n```json\n{\n  \"query\": {\n    \"range\": {\n      \"age\": {\n        \"gte\": 10,\n        \"lte\": 20,\n        \"boost\": 2.0\n      }\n    }\n  }\n}\n```\n\n## Elasticsearch DSL\n\n[https://github.com/cch123/elastic-rs](https://github.com/cch123/elastic-rs)\n\nGrammer\n\n```\nbool_expr = { SOI ~ expr ~ EOI }\n\nexpr = {\n    (paren_bool | comp_expr) ~ ( (and_op|or_op)~ (paren_bool| comp_expr))*\n}\n\nand_op = { \"and\" }\nor_op = { \"or\" }\n\nparen_bool = { \"(\" ~ expr ~  \")\" }\n\ncomp_expr = { field ~ op ~ value }\n\nfield = @{ (ASCII_ALPHA ~ ASCII_ALPHANUMERIC*) }\nop = { eq | neq | op_in | op_not_in | gt | gte | lt | lte | like | not_like }\neq = { \"=\" }\nneq = { \"!=\" | \"<>\"}\nop_in = { \"in\" }\nop_not_in= { \"not\" ~ \"in\"}\ngt = { \">\" }\ngte = { \">=\" }\nlt = { \"<\" }\nlte = { \"<=\" }\nlike = { \"like\" }\nnot_like = { \"not\" ~ \"like\" }\n\nvalue = {\n    string_literal\n    | num_literal\n    | \"(\" ~ string_literal ~(\",\" ~ string_literal)* ~ \")\"\n    | \"(\" ~ num_literal ~(\",\" ~ num_literal)* ~ \")\"\n}\n\nnum_literal = @{\n    \"-\"?\n    ~ (\"0\" | ASCII_NONZERO_DIGIT ~ ASCII_DIGIT*)\n    ~ (\".\" ~ ASCII_DIGIT*)?\n    ~ (^\"e\" ~ (\"+\" | \"-\")? ~ ASCII_DIGIT+)?\n}\n\nstring_literal = ${ \"\\\"\" ~ string ~ \"\\\"\" }\nstring = @{ char* }\nchar = {\n    !(\"\\\"\" | \"\\\\\") ~ ANY\n    | \"\\\\\" ~ (\"\\\"\" | \"\\\\\" | \"/\" | \"b\" | \"f\" | \"n\" | \"r\" | \"t\")\n    | \"\\\\\" ~ (\"u\" ~ ASCII_HEX_DIGIT{4})\n}\n\nWHITESPACE = _{ \" \" | \"\\n\" | \"\\r\" }\n```\n\n## Human language\n\nCommons Range\n\n```bash\nnow\ntoday\ntomorrow\nyesterday\nlast/this/next week\nlast/this/next month\nlast/this/next year\n```\n\nRange\n\n```\n2011\n2011-03\n2011-03-04\n\n2011-03-04 04\n```\n\nAtlas Sample:\n\n- https://atlas.apache.org/#/SearchAdvance\n\nAntlr DSL: [AtlasDSLParser.g4](https://github.com/apache/atlas/blob/master/repository/src/main/java/org/apache/atlas/query/antlr4/AtlasDSLParser.g4)\n\n```sql\nfrom Table select owner as Owner, name as Name, qualifiedName as FullName\n```\n","type":"story"},{"title":"create quake loging attribute","author":"","status":"Doing","priority":"Low","created_date":1639469999,"updated_date":1639469999,"id":23,"content":"\n\n\n","type":"story"},{"title":"pagelink storage","author":"","status":"Spike","priority":"Low","created_date":1639524364,"updated_date":1639524364,"id":24,"content":"\n\nneed a syntax or file for storage items: Hashmap for search and index\n\ngraphviz\n\n```\na -> b\nb -> c\n```\n\nPlantuml\n\n```\na -> b\nb -> c\n```\n\n## idea 0.1: all in one\n\nalso need to index:\n\n```yaml\nnotes:\n - source: 01\n - target:\n     - story: 01, 02, 03, 04\n```\n\n## idea 0.2: one by one\n\nby paths:\n\n```bash\nlinks\n├── blog.yaml\n└── notes.yaml\n```\n","type":"story"},{"title":"Chinese table of content parser","author":"","status":"Spike","priority":"Low","created_date":1639598710,"updated_date":1639598710,"id":25,"content":"\n\n解析中文目录，形成思维导图？\n\n使用的 tag ``@book-toc`\n\n示例：\n\n```\n第一部分 数据系统基础\n第1章 可靠、可扩展与可维护的应用系统 ................... 11\n认识数据系统 ...........................................12\n可靠性 ..................................................14\n可扩展性 ................................................18\n```\n\n\n\n","type":"story"},{"title":"transflow support http/https api and fetch next","author":"","status":"Spike","priority":"Low","created_date":1639613667,"updated_date":1639613667,"id":26,"content":"\n\nrefs: [https://camel.apache.org/manual/rest-dsl.html](https://camel.apache.org/manual/rest-dsl.html)\n\n```java\nrest(\"/say/hello\")\n    .get().route().transform().constant(\"Hello World\");\nrest(\"/say/bye\")\n    .get().consumes(\"application/json\").route().transform().constant(\"Bye World\").endRest()\n    .post().to(\"mock:update\");\n```\n\nSamples:\n\n```\nfrom(\n    rest('https://examples.com/api/blog').next()?\n )\n.to(<quake-network>)\n.map([])\n```\n\nsome config:\n\n1. next link: `.next(field('@'))`;\n2. offsets: `.next(param('offset', 40))`;\n\nand a fetch next API\n\n```\n@Event(): fetchSuccess={(data) => {}}\n@Props(): url;\n@Props(): type\n\nload global quake config;\n\n<fetch-api url=\"@prop\" type=\"github\">\n\n</fetch-api>\n```\n\n","type":"story"},{"title":"create web componnent core api","author":"","status":"Spike","priority":"Low","created_date":1639646139,"updated_date":1639646139,"id":27,"content":"\n\nsuch as:\n\n- http services as data\n- fetch next services\n- as a slot\n\n","type":"story"},{"title":"scripts for auto offline deps","author":"","status":"Spike","priority":"Low","created_date":1639659046,"updated_date":1639659046,"id":28,"content":"\n\n\n1. download ionic\n\nfrom: [https://registry.npmjs.org/@ionic/core/-/core-6.0.1.tgz](https://registry.npmjs.org/@ionic/core/-/core-6.0.1.tgz)\n\n2. download others:\n\nhttps://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.js\n\nhttps://cdn.jsdelivr.net/npm/meilisearch@latest/dist/bundles/meilisearch.umd.js\n\nhttps://unpkg.com/@vaadin/router/dist/vaadin-router.umd.min.js\n\n\n","type":"story"},{"title":"deploy to GitHub pages as demo.","author":"","status":"Spike","priority":"Low","created_date":1639664628,"updated_date":1639664628,"id":29,"content":"\n\n\n1. compile `core/parser` to web assembly\n2. `<fetch-api>` for online deploy\n3. convert data to json files.\n\n","type":"story"},{"title":"dump data for github pages","author":"","status":"Spike","priority":"Low","created_date":1639870094,"updated_date":1639870094,"id":30,"content":"\n\n// 1. dump entries config;\ndump_entries_define();\n// 2. dump quake information;\ndump_transflow();\ndump_layout();\ndump_links();\n// 3. export all entry_type data to json\ndump_entries_data();\n\n\n","type":"story"}]